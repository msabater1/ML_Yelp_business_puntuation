{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a13782",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center\"> <font color='darkorange'>**CUNEF**</font>\n",
    "## <p style=\"text-align:center\"> **Practice III - Models**\n",
    "#### <p style=\"text-align:center\"> **Machine Learning**</strong><br />\n",
    "    \n",
    "<p style=\"text-align:left\">Pablo Mazariegos Reviriego - <font color='orange'>pablo.mazariegos@cunef.edu </font>\n",
    "    \n",
    "<p style=\"text-align:left\">Mario Sabater Pascual - <font color='orange'>mario.sabater@cunef.edu </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858ee63",
   "metadata": {},
   "source": [
    "![Highway](https://www.restaurant-hospitality.com/sites/restaurant-hospitality.com/files/styles/article_featured_retina/public/uploads/2013/07/yelplogopromo.jpg?itok=OM0azJTj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cfd2e",
   "metadata": {},
   "source": [
    "In this Machine Learning practice we will be working with the **Yelp dataset**. The whole practice will be composed by the following notebooks:\n",
    "\n",
    " 0. Data Reading and Problem statement\n",
    " 1. Data selection & variables preparation\n",
    " 2. EDA\n",
    " 3. <font color='darkgreen'>**Model selection**</font>\n",
    " 4. Best Model and Explainability\n",
    "\n",
    "**Creating the prediction Models**\n",
    "\n",
    "\n",
    "\n",
    "[Libraries import and dataset load](#0)\n",
    "\n",
    "[Functions](#25)\n",
    "\n",
    "[Train, Validation and Test split ](#1) \n",
    "\n",
    "## **Models**\n",
    "\n",
    "[Base Model (Dummy)](#2) \n",
    "\n",
    "[Decision Tree Classifier ](#4)\n",
    "\n",
    "[Random Forest Classifier ](#5) \n",
    "\n",
    "[Logistic Regression + Lasso](#10) \n",
    "\n",
    "[Support Vector Machine with Stochastic Gradient Descent](#14) \n",
    "\n",
    "[XGBoost](#7)\n",
    "\n",
    "[LightGBM](#8) \n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "[Score Summary](#15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990c1fa",
   "metadata": {},
   "source": [
    "##  <a name=\"0\"> Libraries import and dataset load  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50796150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.patches import Ellipse\n",
    "import joblib\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804453d1",
   "metadata": {},
   "source": [
    "##  <a name=\"25\"> Functions  </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c12331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_train_test_performance(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    '''Analyze Train and Test Performance'''\n",
    "    \n",
    "    # get predictions\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test  = clf.predict(X_test)\n",
    "    \n",
    "    # get confusion matrices\n",
    "    confmat_train = confusion_matrix(y_train, y_pred_train)\n",
    "    confmat_test  = confusion_matrix(y_test, y_pred_test)\n",
    "    \n",
    "    # Plot confusion matrices and provide metrics\n",
    "    print_performance_metrics(confmat_train, confmat_test)\n",
    "    plot_confusion_matrix(confmat_train, confmat_test)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    y_prob = clf.predict_proba(X_test)[:,1]\n",
    "    plot_roc_curve(y_test,y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad22d3f",
   "metadata": {},
   "source": [
    "Putting ourselves in the selling point of view of the model for predicting what kind of restaurant would be successful.\n",
    "We consider that it is a 'class labels' problem, and within the two possibilities, being a successful restaurant is more important than not being a successful restaurant. \n",
    "Failure would be in the case that an investor makes the investment and does not obtain the predicted results. \n",
    "In conclusion, the necessary metric for this problem is 'f0.5'.\n",
    "\n",
    "The **F0.5 score** is the weighted harmonic mean of the precision and recall (given a threshold value). Unlike the F1 score, which gives equal weight to precision and recall, the F0. 5 score gives more weight to precision than to recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b7b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para f0.5 score:\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def hyper_parameters_search(clf, X, y, param_grid, scorer = fbeta_score, beta=0.5, cv=5):\n",
    "    \n",
    "    grid = GridSearchCV(clf, param_grid = param_grid, scoring = scorer, cv = cv)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "    print(\"best parameters: {}\".format(grid.best_params_))\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a218516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para f1 score:\n",
    "\n",
    "# def hyper_parameters_search(clf, X, y, param_grid, scorer = 'f1', cv=5):\n",
    "    \n",
    "#     grid = GridSearchCV(clf, param_grid = param_grid, scoring = scorer, cv = cv)\n",
    "#     grid.fit(X, y)\n",
    "\n",
    "#     print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "#     print(\"best parameters: {}\".format(grid.best_params_))\n",
    "    \n",
    "#     return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72cfb0",
   "metadata": {},
   "source": [
    "## **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f92bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>food</th>\n",
       "      <th>bars</th>\n",
       "      <th>sandwiches</th>\n",
       "      <th>american (traditional)</th>\n",
       "      <th>pizza</th>\n",
       "      <th>coffee &amp; tea</th>\n",
       "      <th>breakfast &amp; brunch</th>\n",
       "      <th>american (new)</th>\n",
       "      <th>fast food</th>\n",
       "      <th>burgers</th>\n",
       "      <th>mexican</th>\n",
       "      <th>italian</th>\n",
       "      <th>specialty food</th>\n",
       "      <th>seafood</th>\n",
       "      <th>desserts</th>\n",
       "      <th>bakeries</th>\n",
       "      <th>salad</th>\n",
       "      <th>chinese</th>\n",
       "      <th>cafes</th>\n",
       "      <th>chicken wings</th>\n",
       "      <th>ice cream &amp; frozen yogurt</th>\n",
       "      <th>beer</th>\n",
       "      <th>sports bars</th>\n",
       "      <th>cocktail bars</th>\n",
       "      <th>juice bars &amp; smoothies</th>\n",
       "      <th>barbeque</th>\n",
       "      <th>japanese</th>\n",
       "      <th>pubs</th>\n",
       "      <th>sushi bars</th>\n",
       "      <th>local flavor</th>\n",
       "      <th>asian fusion</th>\n",
       "      <th>diners</th>\n",
       "      <th>steakhouses</th>\n",
       "      <th>mediterranean</th>\n",
       "      <th>wine bars</th>\n",
       "      <th>southern</th>\n",
       "      <th>cajun/creole</th>\n",
       "      <th>donuts</th>\n",
       "      <th>tacos</th>\n",
       "      <th>soup</th>\n",
       "      <th>thai</th>\n",
       "      <th>beer bar</th>\n",
       "      <th>tex-mex</th>\n",
       "      <th>greek</th>\n",
       "      <th>breweries</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>chicken shop</th>\n",
       "      <th>hot dogs</th>\n",
       "      <th>indian</th>\n",
       "      <th>bagels</th>\n",
       "      <th>comfort food</th>\n",
       "      <th>cheesesteaks</th>\n",
       "      <th>ethnic food</th>\n",
       "      <th>caribbean</th>\n",
       "      <th>middle eastern</th>\n",
       "      <th>french</th>\n",
       "      <th>soul food</th>\n",
       "      <th>buffets</th>\n",
       "      <th>gastropubs</th>\n",
       "      <th>fruits &amp; veggies</th>\n",
       "      <th>korean</th>\n",
       "      <th>bubble tea</th>\n",
       "      <th>tapas/small plates</th>\n",
       "      <th>food stands</th>\n",
       "      <th>cupcakes</th>\n",
       "      <th>noodles</th>\n",
       "      <th>wineries</th>\n",
       "      <th>cuban</th>\n",
       "      <th>spanish</th>\n",
       "      <th>acai bowls</th>\n",
       "      <th>RestaurantsPriceRange2</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>BYOBCorkage</th>\n",
       "      <th>AgesAllowed</th>\n",
       "      <th>num_days_open</th>\n",
       "      <th>num_hours_open</th>\n",
       "      <th>average_income</th>\n",
       "      <th>RestaurantsDelivery</th>\n",
       "      <th>OutdoorSeating</th>\n",
       "      <th>BusinessAcceptsCreditCards</th>\n",
       "      <th>BikeParking</th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>ByAppointmentOnly</th>\n",
       "      <th>Caters</th>\n",
       "      <th>WheelchairAccessible</th>\n",
       "      <th>RestaurantsReservations</th>\n",
       "      <th>CoatCheck</th>\n",
       "      <th>DogsAllowed</th>\n",
       "      <th>RestaurantsTableService</th>\n",
       "      <th>HasTV</th>\n",
       "      <th>HappyHour</th>\n",
       "      <th>DriveThru</th>\n",
       "      <th>BusinessAcceptsBitcoin</th>\n",
       "      <th>AcceptsInsurance</th>\n",
       "      <th>RestaurantsCounterService</th>\n",
       "      <th>dairy-free</th>\n",
       "      <th>gluten-free</th>\n",
       "      <th>vegan</th>\n",
       "      <th>kosher</th>\n",
       "      <th>halal</th>\n",
       "      <th>soy-free</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>Premium_Parking</th>\n",
       "      <th>Non_Premium_Parking</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_CA</th>\n",
       "      <th>state_FL</th>\n",
       "      <th>state_ID</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MO</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.180427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.237808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.164920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  review_count  is_open  restaurants  food  bars  sandwiches  \\\n",
       "0    1.0      0.009917      1.0          1.0   1.0   0.0         0.0   \n",
       "1    1.0      0.001058      1.0          0.0   1.0   0.0         0.0   \n",
       "2    0.0      0.000132      1.0          1.0   1.0   0.0         1.0   \n",
       "\n",
       "   american (traditional)  pizza  coffee & tea  breakfast & brunch  \\\n",
       "0                     0.0    0.0           1.0                 0.0   \n",
       "1                     0.0    0.0           0.0                 0.0   \n",
       "2                     0.0    0.0           0.0                 0.0   \n",
       "\n",
       "   american (new)  fast food  burgers  mexican  italian  specialty food  \\\n",
       "0             0.0        0.0      0.0      0.0      0.0             0.0   \n",
       "1             0.0        0.0      0.0      0.0      0.0             0.0   \n",
       "2             0.0        1.0      1.0      0.0      0.0             0.0   \n",
       "\n",
       "   seafood  desserts  bakeries  salad  chinese  cafes  chicken wings  \\\n",
       "0      0.0       0.0       1.0    0.0      0.0    0.0            0.0   \n",
       "1      0.0       0.0       0.0    0.0      0.0    0.0            0.0   \n",
       "2      0.0       0.0       0.0    0.0      0.0    0.0            0.0   \n",
       "\n",
       "   ice cream & frozen yogurt  beer  sports bars  cocktail bars  \\\n",
       "0                        0.0   0.0          0.0            0.0   \n",
       "1                        0.0   0.0          0.0            0.0   \n",
       "2                        1.0   0.0          0.0            0.0   \n",
       "\n",
       "   juice bars & smoothies  barbeque  japanese  pubs  sushi bars  local flavor  \\\n",
       "0                     0.0       0.0       0.0   0.0         0.0           0.0   \n",
       "1                     0.0       0.0       0.0   0.0         0.0           0.0   \n",
       "2                     0.0       0.0       0.0   0.0         0.0           0.0   \n",
       "\n",
       "   asian fusion  diners  steakhouses  mediterranean  wine bars  southern  \\\n",
       "0           0.0     0.0          0.0            0.0        0.0       0.0   \n",
       "1           0.0     0.0          0.0            0.0        0.0       0.0   \n",
       "2           0.0     0.0          0.0            0.0        0.0       0.0   \n",
       "\n",
       "   cajun/creole  donuts  tacos  soup  thai  beer bar  tex-mex  greek  \\\n",
       "0           0.0     0.0    0.0   0.0   0.0       0.0      0.0    0.0   \n",
       "1           0.0     0.0    0.0   0.0   0.0       0.0      0.0    0.0   \n",
       "2           0.0     0.0    0.0   0.0   0.0       0.0      0.0    0.0   \n",
       "\n",
       "   breweries  vietnamese  chicken shop  hot dogs  indian  bagels  \\\n",
       "0        0.0         0.0           0.0       0.0     0.0     0.0   \n",
       "1        1.0         0.0           0.0       0.0     0.0     0.0   \n",
       "2        0.0         0.0           0.0       0.0     0.0     0.0   \n",
       "\n",
       "   comfort food  cheesesteaks  ethnic food  caribbean  middle eastern  french  \\\n",
       "0           0.0           0.0          0.0        0.0             0.0     0.0   \n",
       "1           0.0           0.0          0.0        0.0             0.0     0.0   \n",
       "2           0.0           0.0          0.0        0.0             0.0     0.0   \n",
       "\n",
       "   soul food  buffets  gastropubs  fruits & veggies  korean  bubble tea  \\\n",
       "0        0.0      0.0         0.0               0.0     0.0         1.0   \n",
       "1        0.0      0.0         0.0               0.0     0.0         0.0   \n",
       "2        0.0      0.0         0.0               0.0     0.0         0.0   \n",
       "\n",
       "   tapas/small plates  food stands  cupcakes  noodles  wineries  cuban  \\\n",
       "0                 0.0          0.0       0.0      0.0       0.0    0.0   \n",
       "1                 0.0          0.0       0.0      0.0       0.0    0.0   \n",
       "2                 0.0          0.0       0.0      0.0       0.0    0.0   \n",
       "\n",
       "   spanish  acai bowls  RestaurantsPriceRange2  WiFi  Alcohol  Smoking  \\\n",
       "0      0.0         0.0                0.000000   1.0      0.0      0.0   \n",
       "1      0.0         0.0                0.333333   0.0      0.0      0.0   \n",
       "2      0.0         0.0                0.000000   0.0      0.0      0.0   \n",
       "\n",
       "   BYOBCorkage  AgesAllowed  num_days_open  num_hours_open  average_income  \\\n",
       "0          0.0          0.0       1.000000        0.559524        0.180427   \n",
       "1          0.0          0.0       0.666667        0.238095        0.237808   \n",
       "2          0.0          0.0       0.833333        0.392857        0.164920   \n",
       "\n",
       "   RestaurantsDelivery  OutdoorSeating  BusinessAcceptsCreditCards  \\\n",
       "0                  0.0             0.0                         0.0   \n",
       "1                  0.0             0.0                         1.0   \n",
       "2                  1.0             1.0                         1.0   \n",
       "\n",
       "   BikeParking  RestaurantsTakeOut  ByAppointmentOnly  Caters  \\\n",
       "0          1.0                 1.0                0.0     1.0   \n",
       "1          1.0                 1.0                0.0     0.0   \n",
       "2          0.0                 1.0                0.0     0.0   \n",
       "\n",
       "   WheelchairAccessible  RestaurantsReservations  CoatCheck  DogsAllowed  \\\n",
       "0                   0.0                      0.0        0.0          0.0   \n",
       "1                   1.0                      0.0        0.0          0.0   \n",
       "2                   1.0                      0.0        0.0          0.0   \n",
       "\n",
       "   RestaurantsTableService  HasTV  HappyHour  DriveThru  \\\n",
       "0                      0.0    0.0        0.0        0.0   \n",
       "1                      0.0    0.0        0.0        0.0   \n",
       "2                      0.0    1.0        0.0        1.0   \n",
       "\n",
       "   BusinessAcceptsBitcoin  AcceptsInsurance  RestaurantsCounterService  \\\n",
       "0                     0.0               0.0                        0.0   \n",
       "1                     0.0               0.0                        0.0   \n",
       "2                     0.0               0.0                        0.0   \n",
       "\n",
       "   dairy-free  gluten-free  vegan  kosher  halal  soy-free  vegetarian  \\\n",
       "0         0.0          0.0    0.0     0.0    0.0       0.0         0.0   \n",
       "1         0.0          0.0    0.0     0.0    0.0       0.0         0.0   \n",
       "2         0.0          0.0    0.0     0.0    0.0       0.0         0.0   \n",
       "\n",
       "   Premium_Parking  Non_Premium_Parking  state_AZ  state_CA  state_FL  \\\n",
       "0              0.0                  1.0       0.0       0.0       0.0   \n",
       "1              0.0                  1.0       0.0       0.0       0.0   \n",
       "2              0.0                  0.0       0.0       0.0       0.0   \n",
       "\n",
       "   state_ID  state_LA  state_MO  state_PA  state_TN  \n",
       "0       0.0       0.0       0.0       1.0       0.0  \n",
       "1       0.0       0.0       0.0       1.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "restaurants = pd.read_csv('../data/processed/restaurants_models.csv')\n",
    "restaurants.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5c385",
   "metadata": {},
   "source": [
    "##  <a name=\"1\"> Train, Validation and Test split </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e9b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = restaurants['stars'] #isFraud would be our y variable, the one we want to predict\n",
    "X = restaurants.drop('stars', axis = 1) #X would be the whole dataset without the isFraud variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04982648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5146b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4766707193111833"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5412657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47668083975551423"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0df83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCALADO\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# # transform data\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)\n",
    "# #MinMaxScaler preserves the shape of the original distribution.\n",
    "# #It doesn’t meaningfully change the information embedded in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1a65f",
   "metadata": {},
   "source": [
    "##  <a name=\"2\"> Base Model (Dummy) </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b39ff0",
   "metadata": {},
   "source": [
    "The frist model we will work with is a dummy model. A dummy model is said to be a very simple model with a low capacity of prediction. In this case we will predict only for the class 0. Note that, as we are imputing the same class for all the dataset, the model should be a perfect classifier for class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4c6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Initialize Estimator\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "\n",
    "# Check for Model Accuracy\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "y_pred_dummy_prob = dummy_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa47954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      1.00      0.69      7877\n",
      "         1.0       0.00      0.00      0.00      7175\n",
      "\n",
      "    accuracy                           0.52     15052\n",
      "   macro avg       0.26      0.50      0.34     15052\n",
      "weighted avg       0.27      0.52      0.36     15052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f910e",
   "metadata": {},
   "source": [
    "##  <a name=\"4\"> Decision Tree Classifier </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7a682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.606\n",
      "best parameters: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Metric for the scoring\n",
    "scorer = 'recall'\n",
    "\n",
    "# Decision trees\n",
    "param_grid = {'max_depth': range(1, 5)}\n",
    "\n",
    "# Customized function\n",
    "grid_tree = hyper_parameters_search(DecisionTreeClassifier(random_state = 0), \n",
    "                                    X_train , y_train, param_grid, scorer = scorer)\n",
    "\n",
    "# do the plotting\n",
    "#plot_cv_scoring(grid_tree,'max_depth',scorer, plot_errors = True)\n",
    "\n",
    "dt_model =  DecisionTreeClassifier(**grid_tree.best_params_).fit(X_train ,y_train)\n",
    "\n",
    "# joblib.dump(dt_model, \"../models/my_dt.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5bf5c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/my_dt.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_dt \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/my_dt.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m analyze_train_test_performance(loaded_dt,X_train,X_test,y_train,y_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/practica_3/lib/python3.8/site-packages/joblib/numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/my_dt.joblib'"
     ]
    }
   ],
   "source": [
    "loaded_dt = joblib.load(\"../models/my_dt.joblib\")\n",
    "analyze_train_test_performance(loaded_dt,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# set plot dimensions\n",
    "plt.figure(figsize=(35, 10))\n",
    "\n",
    "feature_names=X.columns\n",
    "\n",
    "plot_tree(\n",
    "    dt_model,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['no-fraud','fraud'],\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbfc65",
   "metadata": {},
   "source": [
    "##  <a name=\"5\"> Random Forest Classifier </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63332252",
   "metadata": {},
   "source": [
    "A random forest algorithm consists of a set of decision trees. Each tree gets a ranking and the class that gets the most votes is the winner. The fundamental concept of the random forest is simple but very powerful: small classifiers with little capacity together have a lot of capacity. The low correlation between the models makes their joint predictions more powerful. The reason for this wonderful effect is that the trees protect each other from possible individual errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7732040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#we use the separation criterion gini index to choose the important variables.\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15,random_state=0,\n",
    "n_jobs=-1,oob_score=True,class_weight='balanced').fit(X_train, y_train)\n",
    "# do the plotting\n",
    "#plot_cv_scoring(grid_tree,'max_depth',scorer, plot_errors = True)\n",
    "\n",
    "# joblib.dump(rf, \"../models/my_rf.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_rf = joblib.load(\"../models/my_rf.joblib\")\n",
    "analyze_train_test_performance(loaded_rf,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33c2df",
   "metadata": {},
   "source": [
    "## Feature Importance for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_scores = pd.DataFrame(feature_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(30,24))\n",
    "sns.set(font_scale=1)\n",
    "ax = sns.barplot(x=feature_scores[0], y=feature_scores.index, data=feature_scores)\n",
    "ax.set_title(\"Visualize feature scores of the features\")\n",
    "ax.set_yticklabels(feature_scores.index)\n",
    "ax.set_xlabel(\"Feature importance score\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22b633",
   "metadata": {},
   "source": [
    "Feature importance is important to see how the model makes the decisions it makes. Normally, ML models take variables to be more important that others and of course, this is a good information for us. If a model realies on a variable more than the others it means we have to look at it in a deeper way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cfc606",
   "metadata": {},
   "source": [
    "##  <a name=\"10\"> Logistic Regression + Lasso </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696495b",
   "metadata": {},
   "source": [
    "Logistic + lasso regression\n",
    "In this type of regression we will be using the lasso regularisation, this technique tries to reduce the overfitting (l1). When we do lasso regularisation we are minimizing: $\\sum^{n}_{i=1}(y_{i}- \\sum_{j} x_{ij} \\beta_{j})^{2} + \\lambda \\sum^{p}_{j=1} |\\beta_{j}|$.\n",
    "\n",
    "The tuning parameter, $\\lambda$ controls the strength of the L1 penalty. $\\lambda$ is basically the amount of shrinkage:\n",
    "\n",
    "For $\\lambda$ = 0, no parameters are eliminated. The estimate is equal to the one found with linear regression.\n",
    "As $\\lambda$ increases, more and more coefficients are set to zero and eliminated (theoretically, when $\\lambda$ = $\\infty$, all coefficients are eliminated).\n",
    "As $\\lambda$ increases, bias increases.\n",
    "As $\\lambda$ decreases, variance increases.\n",
    "The logistic regression is based on the logistic function: $\\frac{1}{1 + e^{-x}}$ In the logistic function $x$ is the input variable. For example if we wanted to feed the function values between $(-20,20)$ when we put them in the function, they transform to values between $(0-1)$. As opposed to linear regression where $MSE$ or $RMSE$ is used as the loss function, logistic regression uses a loss function referred to as “maximum likelihood estimation (MLE)” which is a conditional probability. If the probability of fraud is greater than 0.20, the predictions will be classified as class 1. Otherwise, class 0 will be assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Logistic regression\n",
    "#we apply a l1 penalty score so we make it lasso\n",
    "lr_model = LogisticRegression(penalty='l1', solver='liblinear').fit(X_train,y_train)\n",
    "#model.predict_proba(X_train)\n",
    "\n",
    "# save\n",
    "joblib.dump(lr_model, \"../models/my_logistic_reg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676eef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lr = joblib.load(\"../models/my_logistic_reg.joblib\")\n",
    "analyze_train_test_performance(loaded_lr,X_train, X_test ,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41edf6",
   "metadata": {},
   "source": [
    "### How does the model make the decision for the classification between one class and the other?\n",
    "To explain how the algorithm is able to classify one class and another we will use the odds ratio. The odds ratio is the probability of event over the probability of no event, the logistic regression is going to be based on how the prediction changes when one of the features is changed by 1 unit. The odds ratio is calculated: $$\\frac{odds_{x_{j}+1}}{odds} = \\frac{exp(\\beta_{0}+ \\beta_{1}x_{1}+... \\beta_{j}(x_{j}+1)+...+ \\beta_{p}x_{p})}{exp(\\beta_{0}+ \\beta_{1}x_{1}+...+ \\beta_{j}x_{j}+...+ \\beta_{p}x_{p})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds = lr_model.coef_[0]\n",
    "pd.DataFrame(log_odds,\n",
    "             X.columns,\n",
    "             columns=['coef'])\\\n",
    "            .sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59311392",
   "metadata": {},
   "source": [
    "**Remeber that:**\n",
    "\n",
    "- Class 1: is fraud classified.\n",
    "- Class 0: is not fraud classified.\n",
    "\n",
    "\n",
    "To understand the odds ratio, we must first focus on class 1 predictions. For example if the first coefficient oldbalanceOrg increases by 1 unit, the odds represented in the observations targeted as 1 are over $57.67$ times as large as the odds they won't be in the target class. So this means, that if a patient increases his/her oldbalanceOrg by 1 unit, his/her probabilities of being classified as fraud are $57.67$ times higher. The model also relies on other variables such as type_tranfer meaning that if that variable increases by 1 unit, the probabilities of having classified as fraud are 1.27 times higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beaff81",
   "metadata": {},
   "source": [
    "### Feature Selection using ANOVA and Mututal Inforamtion Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.filter_methods import filter_methods_classification\n",
    "filter_methods_classification(X_train_smote, y_train_smote, feat_names = X.columns, rotation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dcdca",
   "metadata": {},
   "source": [
    "##  <a name=\"14\"> Support Vector Machine with Stochastic Gradient Descent </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854588e9",
   "metadata": {},
   "source": [
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence. link-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf24c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "svc=SGDClassifier(random_state=0, loss=\"hinge\").fit(X_train,y_train)\n",
    "calibrator = CalibratedClassifierCV(svc, cv='prefit').fit(X_train, y_train)\n",
    "#scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n",
    "#print(scores.mean())\n",
    "\n",
    "\n",
    "joblib.dump(calibrator, \"../models/my_calibrator.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6719544",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_c = joblib.load(\"../models/my_calibrator.joblib\")\n",
    "analyze_train_test_performance(loaded_c,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4bc3d",
   "metadata": {},
   "source": [
    "##  <a name=\"7\"> XGBoost </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#we use a classifier instead of a regressor because we want to classify wether is a good restaurant or not\n",
    "\n",
    "my_model = XGBClassifier(random_state = 0, n_jobs=-1).fit(X_train ,y_train)\n",
    "\n",
    "joblib.dump(reg, \"../models/my_xgb.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_xgb = joblib.load(\"../models/my_xgb.joblib\")\n",
    "analyze_train_test_performance(loaded_xgb,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29af8e",
   "metadata": {},
   "source": [
    "##  <a name=\"8\"> LightGBM </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Decision trees\n",
    "\n",
    "clf =  lgb.LGBMClassifier(random_state = 0, n_estimators = 20).fit(X_train ,y_train)\n",
    "\n",
    "joblib.dump(clf, \"../models/my_clf.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf = joblib.load(\"../models/my_clf.joblib\")\n",
    "analyze_train_test_performance(loaded_clf,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c12690",
   "metadata": {},
   "source": [
    "##  <a name=\"15\"> Score Summary </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f2008",
   "metadata": {},
   "source": [
    "**Ranking Best Models:**\n",
    "- `LIGHTGBM`\n",
    "- `RandomForest`\n",
    "- `DecisionTree`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d481b7",
   "metadata": {},
   "source": [
    "Practicando graphos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Creamos un grafo vacío\n",
    "G = nx.Graph()\n",
    "\n",
    "# Añadimos los nodos correspondientes a cada restaurante y a cada ciudad\n",
    "for restaurant in restaurants:\n",
    "    G.add_node(restaurant[0], type='restaurant')\n",
    "    G.add_node(restaurant[1], type='city')\n",
    "\n",
    "# Añadimos aristas entre cada restaurante y la ciudad en la que se encuentra\n",
    "for restaurant in restaurants:\n",
    "    G.add_edge(restaurant[0], restaurant[1])\n",
    "\n",
    "# Añadimos nodos adicionales para representar cada categoría de comida y conectamos cada restaurante a las categorías de comida que ofrece\n",
    "for restaurant in restaurants:\n",
    "    for food_category in restaurant[2:]:  # Suponiendo que las categorías de comida están en las posiciones 2 en adelante de la lista\n",
    "        G.add_node(food_category, type='food_category')\n",
    "        G.add_edge(restaurant[0], food_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094e322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f920a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a94c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77b881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a19d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae6901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158420c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_P3_KERNEL",
   "language": "python",
   "name": "ml_p3_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
